{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise03 : Web サービスとして公開する\n",
        "\n",
        "最後にモデルを Web サービスとして公開します。\n",
        "\n",
        "このコードを実行する前に、**[Exercise02 : リモート CPU VM でのトレーニング](./exercise02_train_on_remote.ipynb) でモデルの登録を完了させてください**。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## スコアリング スクリプトの作成 (.py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ウェブサービスとしてデプロイするために、まず以下のようなスコアリングコードを生成します。<br>\n",
        "AML のこのエントリスクリプトは、 ``init()`` と ``run()`` の両方を含む必要があります。\n",
        "\n",
        "> 注意 : サービングコンピュート(VM)は [Managed Identity Endpoint](https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token) を提供します。\n",
        "(スクリプトは、システム割り当てアイデンティティとユーザ割り当てアイデンティティの両方を使用できます)。スクリプトは、安全な情報を提供することなく、Azure リソースのアクセス許可を取得することができます。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/score.py\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from mlflow.pyfunc import load_model\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    \"\"\"\n",
        "    This function is called when the container is initialized/started, typically after create/update of the deployment.\n",
        "    You can write the logic here to perform init operations like caching the model in memory\n",
        "    \"\"\"\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # Please provide your model's folder name if there is one\n",
        "    logging.info(\"AZUREML_MODEL_DIR: \" + os.environ[\"AZUREML_MODEL_DIR\"])\n",
        "\n",
        "    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"models\")\n",
        "    model = load_model(model_path)  \n",
        "    logging.info(\"Init complete\")\n",
        "\n",
        "def run(mini_batch):\n",
        "    \"\"\"\n",
        "    This function is called for every invocation of the endpoint to perform the actual scoring/prediction.\n",
        "    In the example we extract the data from the json input and call the scikit-learn model's predict()\n",
        "    method and return the result back\n",
        "    \"\"\"\n",
        "    logging.info(f\"run method start: {__file__}, run({mini_batch})\")\n",
        "\n",
        "    input = json.loads(mini_batch)[\"data\"]\n",
        "    logging.info(f\"input: {input}\")\n",
        "\n",
        "    predictions = model.predict(input)\n",
        "    logging.info('Predictions:' + str(predictions))\n",
        "    logging.info(\"Request processed\")\n",
        "\n",
        "    return predictions.tolist() # return a dataframe or a list"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## マネージドエンドポイントの作成\n",
        "\n",
        "マネージド オンライン エンドポイントでは、デプロイ トポロジーに **エンドポイント** と **デプロイ** が存在します。<br>\n",
        "1 つのエンドポイントで複数のデプロイを実行し、これらの複数のデプロイに適切なトラフィックを割り当てることができます。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、デプロイ先としてマネージドエンドポイントを作成します。<br>\n",
        "ここで、**``name`` はユニークでなければならないことに注意して、任意のユニークネーム** を指定します。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_name = \"{UNIQUE_ENDPOINT_NAME}\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "さらに以下の ``{UNIQUE_ENDPOINT_NAME}`` を置き換えてください。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 03_managed_endpoint.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
        "name: {UNIQUE_ENDPOINT_NAME}\n",
        "auth_mode: key"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml online-endpoint create --file 03_managed_endpoint.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Studio の左メニュー「エンドポイント」をクリックすると実際にエンドポイントが登録されていることが確認できます。"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web サービスとしてデプロイする\n",
        "次にサービング用のコード (`score.py`) を先のエンドポイントに Web サービスとしてデプロイします。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "デプロイ前に、サービング環境用の conda 設定を作成します。`azureml-defaults` を含める必要があります。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile environments/03_conda_env.yml\n",
        "name: serving_example\n",
        "channels:\n",
        "  - defaults\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8.5\n",
        "  - pip\n",
        "  - pip:\n",
        "      - azureml-defaults\n",
        "      - azureml-mlflow==1.41.0\n",
        "      - scikit-learn==1.0.2\n",
        "      - pandas==1.1.5\n",
        "      - joblib==1.0.0\n",
        "      - matplotlib==3.3.3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "デプロイ用の yaml 設定をして Web サービスをデプロイします。\n",
        "\n",
        "マネージドエンドポイントのモデル（またはコード）を変更した場合、複数のデプロイメントを送信し、トラフィック割り当てを転送しても、混乱は生じません。\n",
        "以下の ``--all-traffic`` オプションを指定すると、すべてのトラフィック (100% トラフィック) がこの単一のデプロイメントに割り当てられます。\n",
        "\n",
        "この例では、Exercise04 で学習したモデルを使用するため、**このコードを実行する前に、\"[Exercise02 : リモート CPU VM でのトレーニング](./exercise02_train_on_remote.ipynb)\" を実行します**。\n",
        "\n",
        "以下の ``{UNIQUE_ENDPOINT_NAME}`` を置き換えてください。\n",
        "\n",
        "> 注意 : 以下の ``instance_count`` を増やすことで、計算をスケールすることができます。(オートスケールの設定も可能です。)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 03_managed_deployment.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
        "name: blue\n",
        "endpoint_name: {UNIQUE_ENDPOINT_NAME}\n",
        "model: azureml:diabetes_model_oh4ml@latest\n",
        "code_configuration:\n",
        "  code: ./scripts\n",
        "  scoring_script: score.py\n",
        "environment: \n",
        "  conda_file: ./environments/03_conda_env.yml\n",
        "  image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
        "instance_type: Standard_DS2_v2\n",
        "instance_count: 1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### デプロイ実行\n",
        "\n",
        "デプロイの完了まで、10 分程度かかります。ML Studio の左メニュー「エンドポイント」をクリックし、エンドポイントの詳細を開くとデプロイの状況について確認できます。"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml online-deployment create --file 03_managed_deployment.yml \\\n",
        "  --all-traffic"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "デプロイエラーが発生した場合、以下のような方法でログを取得できます。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml online-deployment get-logs \\\n",
        "  --endpoint-name $endpoint_name \\\n",
        "  --name blue"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 注意 : クラウド上にデプロイを送信する前に、ローカルの Docker ランタイム上でデプロイし、デバッグすることができます。([こちら](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints)を参照してください)<br>\n",
        "> Visual Studio Code では、ローカルのデプロイにデバッガーをアタッチすることもできます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web サービスをテストする\n",
        "\n",
        "デプロイした Web サービスを呼び出して、返された結果を Python で確認してみましょう。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、デプロイした Web サービスの URI（アドレス）を確認します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml online-endpoint show \\\n",
        "  --name $endpoint_name \\\n",
        "  --query scoring_uri"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "このエンドポイント用のキークレデンシャルを抽出します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml online-endpoint get-credentials \\\n",
        "  --name $endpoint_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "それでは、Python でスコアリング Web サービスを呼び出してみましょう。<br>\n",
        "(** 以下の ``ENDPOINT_URI`` と ``API_KEY`` を自分のものに置き換えてください**)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "SERVING_URI = \"{ENDPOINT_URI}\"\n",
        "API_KEY = \"{API_KEY}\"\n",
        "\n",
        "input = [[0.0380759064334241,0.0506801187398187,0.0616962065186885,0.0218723549949558,-0.0442234984244464,-0.0348207628376986,-0.0434008456520269,-0.00259226199818282,0.0199084208763183,-0.0176461251598052]]\n",
        "\n",
        "# Invoke web service !\n",
        "headers = {\n",
        "    'Content-Type':'application/json',\n",
        "    'Authorization':('Bearer '+ API_KEY)\n",
        "} \n",
        "\n",
        "values = json.dumps(input)\n",
        "input_data = \"{\\\"data\\\": \" + values + \"}\"\n",
        "print(input_data)\n",
        "http_res = requests.post(\n",
        "    SERVING_URI,\n",
        "    input_data,\n",
        "    headers = headers)\n",
        "print('Predicted : ', http_res.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## エンドポイントの削除\n",
        "エンドポイントが不要になった場合、以下のようにして削除できます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#!az ml online-endpoint delete \\\n",
        "#  --name $endpoint_name \\\n",
        "#  --yes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}